{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.CreateTrainingBatches import CreateTrainingBatches\n",
    "from Scripts.Attention import create_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('Data','data_X_y.p'), 'rb') as handle:\n",
    "    data_X_y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('Data','training_params.p'), 'rb') as handle:\n",
    "    training_params = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = training_params['embedding_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = [data_X_y['X_train'],data_X_y['X_valid'], data_X_y['X_test']]\n",
    "y_train, y_valid, y_test = [data_X_y['y_train'],data_X_y['y_valid'], data_X_y['y_test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_training_batches_object = CreateTrainingBatches(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_metrics(np_prob, np_y):\n",
    "    neg_accuracy = np.mean((np_prob<0.5)[(np_y==0)])\n",
    "    pos_accuracy = np.mean((np_prob>0.5)[(np_y==1)])\n",
    "    accuracy = np.mean((pos_accuracy, neg_accuracy))\n",
    "    print('Negative accuracy',neg_accuracy)\n",
    "    print('Positive accuracy',pos_accuracy)\n",
    "    print('Accuracy', accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.int32,shape=[None, 300], name='X')\n",
    "y = tf.placeholder(tf.float32, [None, 1], name='y')\n",
    "tf_keep_prob = tf.placeholder(tf.float32, name='tf_keep_prob')\n",
    "tf_embedding_matrix = tf.Variable(initial_value=embedding_matrix, trainable=False,\n",
    "                                  dtype=tf.float32, name='tf_embedding_matrix')\n",
    "X_embeddings = tf.nn.embedding_lookup(tf_embedding_matrix, X, name='X_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neurons = 50\n",
    "attention_n_neurons = 50\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('RNN', initializer=tf.contrib.layers.xavier_initializer()):\n",
    "    fw_cell = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.GRUCell(num_units=n_neurons), output_keep_prob=tf_keep_prob)\n",
    "    bw_cell = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.GRUCell(num_units=n_neurons), output_keep_prob=tf_keep_prob)\n",
    "    outputs, states = tf.nn.bidirectional_dynamic_rnn(fw_cell, bw_cell, X_embeddings, dtype=tf.float32)\n",
    "with tf.variable_scope('Attention'):\n",
    "    conc_outputs = tf.concat(outputs, 2, name='conc_outputs')\n",
    "    doc_vectors, normalized_attention_scores = create_attention(conc_outputs, attention_n_neurons)\n",
    "    \n",
    "\n",
    "logits = fully_connected(doc_vectors, 1, activation_fn=None)\n",
    "prob = tf.nn.sigmoid(logits, name='prob')\n",
    "\n",
    "x_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits, name='x_entropy')\n",
    "loss = tf.reduce_mean(x_entropy, name='loss')\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss, name='train_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "highest_validation_accuracy = 0.5\n",
    "for i in range(2000):\n",
    "    x_train_samples, y_train_samples = create_training_batches_object.create_training_data()\n",
    "    \n",
    "    _, np_prob, np_y, np_loss = sess.run([training_op, prob, y, loss],\n",
    "                                              feed_dict={X: x_train_samples,\n",
    "                                                         y: y_train_samples,\n",
    "                                                         tf_keep_prob: 0.8})\n",
    "    if i%100==0:\n",
    "        print('Epoch', i, 'Loss',np_loss)\n",
    "        x_valid_samples, y_valid_samples = create_training_batches_object.create_validation_data()\n",
    "\n",
    "        np_prob, np_y, np_loss = sess.run([prob, y, loss],\n",
    "                                                  feed_dict={X: x_valid_samples,\n",
    "                                                             y: y_valid_samples,\n",
    "                                                             tf_keep_prob: 1})\n",
    "        validation_accuracy = print_metrics(np_prob, np_y)\n",
    "        if validation_accuracy > highest_validation_accuracy:\n",
    "            print('Saved model with highest accuracy')\n",
    "            saver.save(sess, os.path.join('Models', 'tf_models','model.ckpt'))\n",
    "            highest_validation_accuracy = validation_accuracy\n",
    "        print('-----------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
