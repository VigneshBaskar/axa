{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Scripts.CreateTrainingBatches import CreateTrainingBatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('Data','data_X_y.p'), 'rb') as handle:\n",
    "    data_X_y = pickle.load(handle)\n",
    "\n",
    "with open(os.path.join('Data','training_params.p'), 'rb') as handle:\n",
    "    training_params = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = [data_X_y['X_train'],data_X_y['X_valid'], data_X_y['X_test']]\n",
    "y_train, y_valid, y_test = [data_X_y['y_train'],data_X_y['y_valid'], data_X_y['y_test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_size = training_params['vocab_size']\n",
    "mlb = MultiLabelBinarizer()\n",
    "X_valid = mlb.fit_transform(X_valid)\n",
    "X_train = mlb.fit_transform(X_train)\n",
    "create_training_batches_object = CreateTrainingBatches(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_metrics(np_prob, np_y):\n",
    "    neg_accuracy = np.mean((np_prob<0.5)[(np_y==0)])\n",
    "    pos_accuracy = np.mean((np_prob>0.5)[(np_y==1)])\n",
    "    accuracy = np.mean((pos_accuracy, neg_accuracy))\n",
    "    print('Negative accuracy',neg_accuracy)\n",
    "    print('Positive accuracy',pos_accuracy)\n",
    "    print('Accuracy', accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "doc_vectors = tf.placeholder(dtype=tf.float32,shape=[None, vocab_size], name='doc_vectors')\n",
    "y = tf.placeholder(tf.float32, [None, 1], name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_one_output = fully_connected(doc_vectors, 100, activation_fn=tf.nn.relu)\n",
    "logits = fully_connected(layer_one_output,1, activation_fn=None)\n",
    "prob = tf.nn.sigmoid(logits, name='prob')\n",
    "\n",
    "x_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits, name='x_entropy')\n",
    "loss = tf.reduce_mean(x_entropy, name='loss')\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss, name='train_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter('tf_logs/logistic_regression', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "highest_validation_accuracy = 0.5\n",
    "for i in range(2000):\n",
    "    x_train_samples, y_train_samples = create_training_batches_object.create_training_data()\n",
    "    \n",
    "    _, np_prob, np_y, np_loss = sess.run([training_op, prob, y, loss],\n",
    "                                              feed_dict={doc_vectors: x_train_samples,\n",
    "                                                         y: y_train_samples})\n",
    "    if i%100==0:\n",
    "        print('Epoch', i, 'Loss',np_loss)\n",
    "        x_valid_samples, y_valid_samples = create_training_batches_object.create_validation_data()\n",
    "\n",
    "        np_prob, np_y, np_loss = sess.run([prob, y, loss],\n",
    "                                                  feed_dict={doc_vectors: x_valid_samples,\n",
    "                                                             y: y_valid_samples})\n",
    "        validation_accuracy = print_metrics(np_prob, np_y)\n",
    "        if validation_accuracy > highest_validation_accuracy:\n",
    "            print('Saved model with highest accuracy')\n",
    "            saver.save(sess, os.path.join('Models', 'tf_models','model.ckpt'))\n",
    "            highest_validation_accuracy = validation_accuracy\n",
    "        print('-----------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
